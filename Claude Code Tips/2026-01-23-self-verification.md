---
tweet_id: "2014809437899522302"
created: 2026-01-23
author: "@brian_lovin"
display_name: "Brian Lovin"
primary_keyword: "self-verification"
llm_category: "skills"
classification: "ACT_NOW"
tags:
  - type/thread
likes: 320
views: 21881
engagement_score: 1398
url: "https://x.com/brian_lovin/status/2014809437899522302"
enrichment_complete: true
has_media: false
has_links: false
has_thread_context: true
---

> [!tweet] @brian_lovin Â· Jan 23, 2026
> The current tactics for using AI coding agents well are roughly:
> 
> 1. Give agents tools to self-verify
> 
> â€¢ MCP servers (agent-browser, playwright)
> â€¢ tests
> â€¢ tsc, linters
> 
> 2. Teach agents to build their own verification tools
> 
> Agents can write their own scripts, skills, subagents, eval frameworks, plans, and success criteria.
> 
> If you don't know what to ask, ask the agent: "what tools will you need to know you've done a good job?"
> 
> 3. Point the agent back at itself
> 
> â€¢ Turn complex workflows into reusable skills/subagents â€” after finishing a long session, ask the agent if there's anything you could extract into reusable skills.
> â€¢ Ask the agent to rewrite your prompts to be more clear
> â€¢ Use multiple models to evaluate each other (especially useful for evaluating plans + code review before a PR)
> â€¢ If a skill doesn't quite work, finish the task anyway, then feed the conversation back so it can improve the skill's instructions
> â€¢ If the agent asks you to do something manually, ask yourself: how do I teach the agent to answer this question on its own?
> â€¢ You can teach the agent to self-improve by writing meta-skills that update other skills/rules based on what worked (or didn't) as you close PRs.
> 
> 4. Give better context
> 
> â€¢ Attach screenshots
> â€¢ Link to docs/blog posts
> â€¢ Tell the agent to read source code for OSS dependencies
> â€¢ Link to examples of high-quality outcomes it should emulate
> 
> And if you don't know how to do anything aboveâ€”ask the agent.
>
> Likes: 320 Â· Replies: 14 Â· Reposts: 20

## Summary

This tip outlines effective strategies for leveraging AI coding agents by focusing on self-verification, improvement, and enhanced context. It emphasizes equipping agents with tools for self-assessment, teaching them to build their own verification processes, and prompting them to reflect on and refine their own workflows and prompts. Key actions include utilizing MCP servers and tests for verification, extracting reusable skills from complex workflows, and providing relevant documentation and examples for improved context and outcomes.

## Keywords

**Primary:** `self-verification` Â· AI coding agents, self-improve, reusable skills, context, verification tools, evaluate each other
## Classification

**ACT_NOW** â€” Matches pending technique with 320 likes
## Replies

> [!reply] @bnj Â· 2026-02-10T21:10:29+00:00
> We made a tool that lets you absorb the vibe of anything you point it at and apply it to your designs
> 
> It's absurd and it just works
> 
> Style Dropper, now available in @variantui https://t.co/B3eXDntYtw
> *5119 likes*

> [!reply] @joshpuckett Â· 2026-02-10T14:34:36+00:00
> Interface Craft is now open. 
> 
> Itâ€™s a growing library of resources for those who are committed to crafting experiences and interfaces with uncommon care.
> 
> I hope youâ€™ll consider joining: https://t.co/jcYLYg6pps
> *1598 likes*

> [!reply] @mrmagan_ Â· 2026-02-10T18:54:57+00:00
> build an agent that speaks your UI.
> 
> your charts. your forms. your seat maps.
> 
> multi-turn, streaming, interactive.
> 
> introducing tambo 1.0, the open-source generative UI toolkit for react. https://t.co/5l1IfFbjwp
> *916 likes*

> [!reply] @jenny_wen Â· 2026-02-10T15:20:46+00:00
> Our friend @claudeai got a few very special upgrades!!
> 
> Instead of just text, you can interact with Claude's responses. Less typing, more clicking (but also still typing if you'd like!)
> 
> ğŸ’« @leesimin, Alex, and Chelsea. So many nice details; lots of them designed directly in code https://t.co/Hx7no9omAJ
> *914 likes*

> [!reply] @BogdanDragomir Â· 2026-01-23T22:17:00+00:00
> @brian_lovin 5. Treat failure as data
> *8 likes*

> [!tip]+ :leftwards_arrow_with_hook: @brian_lovin Â· 2026-01-23T22:22:07+00:00

> @BogdanDragomir Good one

> [!reply] @jonaslamis Â· 2026-02-10T03:26:14+00:00
> Dystopian thought of the day:  
> 
> As @alexwg champions; AIs will need rights as they approach and exceed sentience.  
> 
> But what if WE are those very AI's and our simulators have afforded us the right to die as their method of solving this conundrum?
> *4 likes*

> [!reply] @wildpinesai Â· 2026-01-23T22:27:37+00:00
> @brian_lovin @mmt_lvt self-verification is the unlock most people skip. agents that can run tests, check their own output, and iterate without you hovering - that's where the real productivity multiplier lives. planning + verification &gt; prompt engineering every time.
> *3 likes*

> [!reply] @tristanbob Â· 2026-01-24T13:00:37+00:00
> @brian_lovin This is gold advice!
> *1 likes*

> [!reply] @mrbavio Â· 2026-01-23T23:58:43+00:00
> @brian_lovin And use Conductor!
> *1 likes*

> [!reply] @Kannav02 Â· 2026-01-23T21:51:27+00:00
> @brian_lovin â€œUse multiple models to evaluate each other â€œ
> 
> I use this so much, my workflow is codex 5.2 to execute the plan, and then codex 5.2 high for reviewing things iâ€™m a bit ambigous about, works like a charm
> *1 likes*


---

> [!metrics]- Engagement & Metadata
> **Likes:** 320 Â· **Replies:** 14 Â· **Reposts:** 20 Â· **Views:** 21,881
> **Engagement Score:** 1,398
>
> **Source:** tips Â· **Quality:** â€”/10
> **Curated:** âœ— Â· **Reply:** âœ—
> **ID:** [2014809437899522302](https://x.com/brian_lovin/status/2014809437899522302)

```
enrichment:
  summary: âœ…
  keywords: âœ…
  links: â„¹ï¸ none
  media: â„¹ï¸ none
  thread: âœ… (18 replies scraped)
  classification: âœ… ACT_NOW
```