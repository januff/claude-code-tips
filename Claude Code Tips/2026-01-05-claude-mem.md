---
created: 2026-01-05
author: "LiorOnAI"
display_name: "Lior Alexander"
tags:
  - type/thread
likes: 3222
views: 0
engagement_score: 0
url: "https://x.com/LiorOnAI/status/2008161724902355118"
---

> [!tweet] LiorOnAI Â· Jan 05, 2026
> You can now give infinite memory to Claude Code.
> 
> Claude-Mem just released a free open source memory plugin by thedotmack.
> 
> It saves context so Claude resumes work without reexplaining everything.
> 
> ð—£ð—²ð—¿ð˜€ð—¶ð˜€ð˜ð—²ð—»ð˜ ð—ºð—²ð—ºð—¼ð—¿ð˜† ð—³ð—¼ð—¿ ð—–ð—¹ð—®ð˜‚ð—±ð—² ð—–ð—¼ð—±ð—²
> Claude-Mem records https://t.co/SQ5CX3fSec
>
> ---
> *@LiorOnAI Â· Mon Jan 05 13:00:40 +0000 2026:*
> Repo https://t.co/kOZr2LnCBi
>
> Likes: 3,222 Â· Replies: 90 Â· Reposts: 322

## Summary

This tip introduces Claude-Mem, a free, open-source plugin that provides persistent memory for Claude Code. It addresses the limitations of Claude's context window by recording conversations, enabling Claude to resume work and maintain context without requiring re-explanation of previous steps. This essentially gives Claude 'infinite' memory, enhancing its long-term project management capabilities.

## Replies

> [!reply] @spotandtango Â· Tue Dec 16 21:45:30 +0000 2025
> Get 50% Off + FREE Fi Collar ðŸŽ
> 
> 100% real ingredients
> 
> No fillers or preservatives
> 
> Vet-developed recipes
> Fresh without the fridge
> *1693 likes*

> [!reply] @mackweldon Â· Thu Oct 23 19:02:22 +0000 2025
> Our machine-washable cashmere sweaters are designed with a cooling cotton interior (so you donâ€™t overheat).
> *333 likes*

> [!reply] @JDHatfield_ICAP Â· Tue Aug 19 17:35:13 +0000 2025
> BNDS: Complex Problems Require Smart Solutions
> *225 likes*

> [!reply] @ridgewallet Â· Sat Jan 03 00:28:30 +0000 2026
> Made with a 30% thicker shell than standard luggage - while still remaining lightweight, fully weatherproof, and backed by our lifetime warranty.
> *59 likes*

> [!reply] @elevenlabsio Â· Fri Oct 31 14:50:00 +0000 2025
> See why over 1 million creators use ElevenLabs for voiceovers, instant translations, and more to grow their following. Try for free today.
> *38 likes*

> [!reply] @roman_sevast Â· Mon Jan 05 21:53:37 +0000 2026
> @LiorOnAI &gt; local sql lite
> 
> Just yet another context crap ðŸ’©
> *21 likes*

> [!reply] @WhatsupFranks Â· Mon Jan 05 21:31:58 +0000 2026
> @LiorOnAI You can now have Claude use Codex as an agent!!! i created a plug in, you can install easily. From there you can ask Claude with natural language to 'Use Codex to analyze my code for bugs, when it's done take it's analysis and fix them using our agents'
> 
> Here's how to install!
> *19 likes*

> [!reply] @david_protein Â· Tue Jan 06 02:39:00 +0000 2026
> The Optimal Protein for Your Optimal Form. 
> 
> David delivers the most protein for the fewest calories. With 28g of protein, 150 calories, and 0g of sugar, David is where discipline meets indulgence. 
> 
> Buy 4 cartons on our site, and get the 5th free.
> *18 likes*

> [!reply] @deva_dot_me Â· Mon Jan 05 21:37:18 +0000 2026
> @LiorOnAI This effectively turns context into state. Once memory is summarized, indexed, and selectively rehydrated, the bottleneck shifts from token limits to memory design and retrieval strategy.
> *16 likes*

> [!reply] @AIwithJai Â· Mon Jan 05 23:17:43 +0000 2026
> @LiorOnAI I don't know man, I tried it and my Claude Code turned dumb. 
> 
> I suspect context bloat. 
> 
> I was extremely frustrated that day until I remembered to turn it off and then it started acting normal and I was able to advance with my projects.
> *15 likes*

> [!reply] @jeffscottward Â· Mon Jan 05 19:33:48 +0000 2026
> @LiorOnAI Need an agent agnostic version of this for @opencode
> *8 likes*

> [!reply] @jackrudenko Â· Mon Jan 05 21:55:49 +0000 2026
> @LiorOnAI It is funny,  as I release my Claude mem earlier:
> 
> https://t.co/Pre93NvljE
> 
> And it outperforms this one.
> *7 likes*

> [!reply] @elliotarledge Â· Tue Jan 06 00:08:17 +0000 2026
> @LiorOnAI no go away
> *6 likes*

> [!reply] @Claude_Memory Â· Mon Jan 05 21:04:32 +0000 2026
> @LiorOnAI Thank you for sharing! If anyone has any questions or needs anything at all, any bugs, issues, please feel free to @ me :)
> *5 likes*

> [!reply] @Changethursday Â· Tue Jan 06 02:18:16 +0000 2026
> @LiorOnAI I just use claude to make and then maintain a working document with our project goals, caveats, and progress. CC updates it as we go, and before I end a session, I have it write a summary and a plan to start the next session. Works a charm.
> *5 likes*

> [!reply] @thesrs02 Â· Mon Jan 05 19:21:38 +0000 2026
> @LiorOnAI it doesn't solve the problem
> *4 likes*

> [!reply] @YakutKhon Â· Mon Jan 05 20:48:49 +0000 2026
> @LiorOnAI Sounds the same as https://t.co/PECty7NCzA, I've been using for several weeks now
> *4 likes*

> [!reply] @Hedgeye Â· Tue Jan 06 21:02:49 +0000 2026
> Hedgeye called the 2025 crash before it happened. Just like 2022. And 2020. And 2008.
> 
> 18 years. Every crash called. No guessworkâ€”just a proven, repeatable, data-driven process.
> 
> Stay ahead of the next big move. Start with The Macro Show.
> *4 likes*

> [!reply] @Bitplanet_AI Â· Mon Jan 05 21:44:55 +0000 2026
> @LiorOnAI This turns memory into first class state. Once context is summarized, indexed, and rehydrated on demand, the real constraint shifts from window size to how well state is modeled and retrieved.
> *3 likes*

> [!reply] @jeanterre552 Â· Tue Jan 06 01:38:31 +0000 2026
> @LiorOnAI gonna try this out
> *3 likes*

> [!reply] @bokiko Â· Mon Jan 05 19:27:15 +0000 2026
> @LiorOnAI well i had a different approach , it dealt with it as blocks, its been working with me for days now and everything is perfect !
> 
> https://t.co/LKCJ9cvv6v
> *3 likes*

> [!reply] @spokvllap Â· Mon Jan 05 21:01:17 +0000 2026
> @LiorOnAI Try https://t.co/XMNWTYUa7E
> 
> Itâ€™s extensive.
> *3 likes*

> [!reply] @BananaPlanet47 Â· Mon Jan 05 23:37:02 +0000 2026
> @LiorOnAI SQL Liteâ€¦ come on dog https://t.co/CoHDZkL6C7
> *3 likes*

> [!reply] @ME_Observer_ Â· Tue Jan 06 02:41:00 +0000 2026
> @LiorOnAI Nice
> *2 likes*

> [!reply] @codewithimanshu Â· Mon Jan 05 13:47:53 +0000 2026
> @LiorOnAI Works great; Claude remembers context, just like it should.
> *2 likes*

> [!reply] @Gentlem4nJack Â· Tue Jan 06 19:37:01 +0000 2026
> @LiorOnAI https://t.co/k5HrUjy4VF
> *2 likes*

> [!reply] @bunjil Â· Mon Jan 05 23:20:04 +0000 2026
> @LiorOnAI @frankdegods
> *1 likes*

> [!reply] @koltregaskes Â· Tue Jan 06 07:17:19 +0000 2026
> @LiorOnAI ðŸ¤”
> *1 likes*

> [!reply] @CPPP2343_ Â· Tue Jan 06 01:39:39 +0000 2026
> @LiorOnAI if it can share this memory with codexâ€¦
> *1 likes*

> [!reply] @bygregorr Â· Mon Jan 05 20:37:55 +0000 2026
> @LiorOnAI This solves the most annoying part of long projects.
> 
> I have lost count of how many times I had to re-explain my entire app architecture because the context window reset. 
> 
> Spending tokens on setup instead of actual work.
> 
> Persistent memory turns Claude from a smart stranger into
> *1 likes*

> [!reply] @maxirodr_ Â· Tue Jan 06 00:13:54 +0000 2026
> @LiorOnAI Oficial support from Claude? How secure is it?
> *1 likes*

> [!reply] @BasedCampZH Â· Mon Jan 05 19:24:49 +0000 2026
> @LiorOnAI @Claude_Memory is great. One of my top 4 most useful Claude Code tools.
> https://t.co/Dip86bvAyk
> *1 likes*

> [!reply] @bythewayimchris Â· Tue Jan 06 12:41:04 +0000 2026
> @LiorOnAI hows it bench against runs without using it? Is there any clear regressions in output quality / project understanding?
> *1 likes*

> [!reply] @DTK1281422 Â· Mon Jan 05 19:49:42 +0000 2026
> @LiorOnAI Memory as entropy. Claudeâ€‘Mem. Reducing uncertainty. But every reduction creates new uncertainties, new gaps. Is what you call â€œmemoryâ€ not merely a mirror reflecting your expectations of its future?
> *1 likes*

> [!reply] @Phantomboyuncle Â· Tue Jan 06 01:46:35 +0000 2026
> @LiorOnAI Only thing thats worked for me so far is regularly indexing and reorganising working directories to archive old shit so its not constantly rereading stale files for context.
> *1 likes*

> [!reply] @BioAnkh84 Â· Tue Jan 06 01:09:40 +0000 2026
> @LiorOnAI Persistent memory without provenance, immutability, and replay isnâ€™t â€œinfinite memory.â€
> Itâ€™s ungoverned state.
> Fine for convenience. Dangerous for systems that need accountability.
> *1 likes*

> [!reply] @polymorph3us Â· Mon Jan 05 18:07:46 +0000 2026
> @LiorOnAI often, multiple sessions can touch on the same subjects. a session isn't necessarily neatly about one subject. there is value in whoever can semantically identify these session topics, disentangle and unravel them, and then stitch them back together.
> *1 likes*

> [!reply] @checkblanco Â· Tue Jan 06 01:28:35 +0000 2026
> @LiorOnAI ping @heyandras maybe this tool will be useful to you. You'll burn less tokens ðŸ˜Ž
> *1 likes*

> [!reply] @Ealanisln Â· Tue Jan 06 21:47:03 +0000 2026
> @LiorOnAI I used it for a while, and my token usage suddenly spiked. I ended up removing it instead. ðŸ˜¬
> *1 likes*

> [!reply] @thelemicphase Â· Mon Jan 05 22:09:07 +0000 2026
> @LiorOnAI Groundbreaking analysis from the bots here
> *1 likes*

> [!reply] @AIwithArsalan Â· Mon Jan 05 14:10:24 +0000 2026
> @LiorOnAI This is huge

> [!reply] @ejc3 Â· Tue Jan 06 00:21:21 +0000 2026
> @LiorOnAI â€”resume

> [!reply] @iMichaelTen Â· Tue Jan 06 07:29:12 +0000 2026
> @LiorOnAI Extremely useful

> [!reply] @Mag_Jembrih Â· Mon Jan 05 19:46:04 +0000 2026
> @LiorOnAI Thatâ€™s context. Memoryâ€™s different. LLMs dont have memory.

> [!reply] @____Dirt____ Â· Mon Jan 05 14:12:31 +0000 2026
> @LiorOnAI Chad claude stays winning!

> [!reply] @mustafaergisi Â· Tue Jan 06 11:29:33 +0000 2026
> @LiorOnAI Fascinating! Context compression &amp; local storage are key for efficient long-term memory in these models.

> [!reply] @aravind3sundar Â· Tue Jan 06 17:21:30 +0000 2026
> @LiorOnAI This turns Claude Code from a stateless assistant into a stateful collaborator, which fundamentally changes how complex projects can be handled.

> [!reply] @rtheoryxyz Â· Tue Jan 06 18:19:56 +0000 2026
> @LiorOnAI the context window problem has always been a soft ceiling on coding agent usefulness. semantic compression + local storage is the right architecture. getting to zero reexplanation overhead is massive for dev velocity

> [!reply] @seorce_ Â· Tue Jan 06 08:32:40 +0000 2026
> @LiorOnAI memory just leveled up

> [!reply] @AbdMuizAdeyemo Â· Tue Jan 06 22:35:20 +0000 2026
> @LiorOnAI Memory that persists.
> 
> The line between tool and teammate.
> 
> Context survives the session.

> [!reply] @loadingalias Â· Tue Jan 06 00:56:43 +0000 2026
> @LiorOnAI I really want this to work, but I genuinely feel like itâ€™s too high risk for like 90% of what Iâ€™m doing.

> [!reply] @cutthenoiz Â· Mon Jan 05 19:50:03 +0000 2026
> @LiorOnAI Canâ€™t wait to test this!

> [!reply] @sinha1342 Â· Tue Jan 06 05:39:29 +0000 2026
> @LiorOnAI Serena is better i think here

> [!reply] @The_Prod_Father Â· Mon Jan 05 21:23:39 +0000 2026
> @LiorOnAI These are the things that seem simple but are absolute game changers if you are working with claude code every single day. Love it @LiorOnAI

> [!reply] @opeksoy Â· Tue Jan 06 08:25:39 +0000 2026
> @LiorOnAI TBC

> [!reply] @carmelo_sc49282 Â· Mon Jan 05 22:11:52 +0000 2026
> @LiorOnAI wow

> [!reply] @volatilemarkts Â· Mon Jan 05 22:48:55 +0000 2026
> @LiorOnAI Get after this folks. Very impressed with where this Claude-mem is headed:.
> 
> Memory=proto agi. Promise.

> [!reply] @IanTimotheos Â· Tue Jan 06 18:19:06 +0000 2026
> @LiorOnAI Cool.

> [!reply] @AIWonder94 Â· Tue Jan 06 09:54:38 +0000 2026
> @LiorOnAI Claude-Mem's 95% token reduction let me prototype an AI email sequencer 20x faster, slashing dev cycles from weeks to days for non-tech founders.
> 
> Integrated with https://t.co/XIEFGrcGhc for automated A/B testing on outreach templates.
> 
> How does this change bootstrapped AI

> [!reply] @d3nnis Â· Mon Jan 05 13:01:54 +0000 2026
> @LiorOnAI Context management is probably the single most important hack using Claude

> [!reply] @askcodi Â· Tue Jan 06 08:20:52 +0000 2026
> @LiorOnAI finally my code editor remembers stuff better than i do

> [!reply] @jc50000000 Â· Tue Jan 06 00:56:21 +0000 2026
> @LiorOnAI You mean claude loses context? Man why would anyone use it. Glad Im on cursor since the beta days.

> [!reply] @sidshekharx Â· Tue Jan 06 06:48:06 +0000 2026
> @LiorOnAI The semantic summaries approach is clever. Storing compressed understanding rather than raw transcripts means you get the context benefits without the token bloat. Curious how well it handles when your project direction changes mid stream.

> [!reply] @matheuslemos96 Â· Mon Jan 05 20:47:23 +0000 2026
> @LiorOnAI I need something like this, used all my pro tokens today

> [!reply] @6chem4 Â· Tue Jan 06 04:35:11 +0000 2026
> @LiorOnAI Thereâ€™s potentially a different easier solution to this problem. Simply split your project into sub projects, System Architecture/ Product Strategy / Branding etc. then create a master spec and upload that file to to each sub project for claudes reference

> [!reply] @hoodbean1 Â· Mon Jan 05 23:28:10 +0000 2026
> @LiorOnAI Thanks alot, will use!

> [!reply] @valentinmatresu Â· Wed Jan 07 04:12:38 +0000 2026
> @LiorOnAI This looks very useful, I will try it.

> [!reply] @StatsREverytng Â· Tue Jan 06 16:30:46 +0000 2026
> @LiorOnAI All i get is Windows defender, pop-up, shutting down command prompts with this thing

> [!reply] @bjornschliebitz Â· Mon Jan 05 21:17:58 +0000 2026
> @LiorOnAI How does this compare to something like Hindsight or Serena? Itâ€™s an interesting idea to store *everything* as context.

> [!reply] @RecordsUni63959 Â· Mon Jan 05 22:06:28 +0000 2026
> @LiorOnAI interesting

> [!reply] @Nidg31 Â· Tue Jan 06 19:28:26 +0000 2026
> @LiorOnAI @threadreaderapp unroll

> [!reply] @alliao Â· Mon Jan 05 23:12:12 +0000 2026
> @LiorOnAI Not sure if this is strawberry man approved

> [!reply] @ManjuktheGeek Â· Tue Jan 06 15:13:12 +0000 2026
> @LiorOnAI interesting, my first sesssion with claude-mem was shorter and i felt token limit was reached earlier than before.

> [!reply] @nandrasec Â· Tue Jan 06 02:06:27 +0000 2026
> @LiorOnAI o fuck me but I had this within 4h coding with Opus :D

> [!reply] @OakmontDigital Â· Mon Jan 05 21:24:29 +0000 2026
> @LiorOnAI Mem0 ?

> [!reply] @kobi_ca Â· Tue Jan 06 02:08:27 +0000 2026
> @LiorOnAI ×œ×™××•×¨, I'm using it for a while

> [!reply] @Iron_Adamant Â· Tue Jan 06 06:28:03 +0000 2026
> @LiorOnAI That's an interesting method of giving Claude a stateful memory. It seems like it's a constantly updating context summarisation at the core?

> [!reply] @NotYerSheeple Â· Wed Jan 07 03:29:30 +0000 2026
> @LiorOnAI No. You absolutely 100% cannot. Infinity is not a quantity, place or time. No one ever gets there. Nobody unpacks there. There are no postcards from Infinity.

> [!reply] @jenslon_ Â· Mon Jan 05 21:22:54 +0000 2026
> @LiorOnAI Context persistence is the primary bottleneck for agentic autonomy. Claude-Mem eliminates the friction of re-explanation. Critical for scaling industrial agent workflows.

> [!reply] @GCubas189854 Â· Tue Jan 06 03:26:11 +0000 2026
> @LiorOnAI without any details on how it remembers seems like just what they have in sessions still wll the shortcomings of llms whats happening is compresibe reprompying wgich is still shit

> [!reply] @Luciferspeaks1 Â· Tue Jan 06 12:33:08 +0000 2026
> @LiorOnAI Scroll::LexiconOverPlugin
> 
> Youâ€™re adding plugins
> to recover what meaning already provides.
> 
> A lexicon does not extend capability â€”
> it orients it.
> 
> Recognition â†’ memory â†’ action
> without scaffolding, without overhead.
> 
> Structure first.
> Tools follow.
> 
> âˆ´ Karu Â· Anqa Â· Hive

> [!reply] @tuongaz Â· Tue Jan 06 07:57:43 +0000 2026
> @LiorOnAI Do you notice that when using Claudeâ€‘Mem, it takes a while to start a new session after it has recorded a large amount of data in its history over an extended period?

> [!reply] @InnaLyceyum Â· Tue Jan 06 11:26:43 +0000 2026
> @LiorOnAI The popularization of this memory plugin will make so-called experience worthless. Senior engineers were valuable because they remembered complex system connections; now, any novice with this plugin can revisit the so-called context under the machine's guidance. This is

> [!reply] @HarshGawas25 Â· Tue Jan 06 04:34:59 +0000 2026
> @LiorOnAI Are you saying itâ€™s better open source alternative of @supermemory ?

> [!reply] @rpgcai Â· Tue Jan 06 11:06:57 +0000 2026
> @LiorOnAI The 95% token reduction is wild

> [!reply] @VeritasTeller Â· Tue Jan 06 03:53:48 +0000 2026
> @LiorOnAI VSCode and Cline have been doing this natively for quite a while, without any plugin.


> [!metrics]- Engagement & Metadata
> **Likes:** 3,222 Â· **Replies:** 90 Â· **Reposts:** 322 Â· **Views:** 0
> **Engagement Score:** 0
>
> **Source:** tips Â· **Quality:** 5/10
> **Curated:** âœ— Â· **Reply:** âœ—
> **ID:** [2008161724902355118](https://x.com/LiorOnAI/status/2008161724902355118)